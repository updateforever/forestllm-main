{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义模型数据\n",
    "models = [\n",
    "    \"Faster R-CNN\", \"Cascade R-CNN\", \"YOLOV5n\", \"YOLOV8n\", \"YOLOV10n\", \"YOLOV11n\", \n",
    "    \"YOLOV5s\", \"YOLOV8s\", \"YOLOV10s\", \"YOLOV11s\", \"RT-DETR\", \"RT-DETRv2\", \"DINO\", \"MSAR-T\", \"MSAR-B\"\n",
    "]\n",
    "\n",
    "gflops = [91.3, 119.0, 7.1, 8.1, 8.4, 6.4, 23.8, 28.4, 24.4, 21.6, 130.5, 100.5, 119.0, 12.2, 47.8]\n",
    "map_values = [51.7, 47.9, 67.2, 74.2, 63.4, 68.8, 68.9, 79.9, 73.4, 76.1, 53.8, 64.0, 57.0, 76.3, 81.9]\n",
    "params = [41.7, 69.4, 2.5, 3.0, 2.7, 2.6, 9.1, 11.1, 8.0, 9.4, 42.7, 36.4, 47.5, 5.5, 20.7]\n",
    "\n",
    "# 归一化气泡大小\n",
    "bubble_size = np.array(params) * 10\n",
    "\n",
    "# 颜色区分不同算法\n",
    "colors = [\n",
    "    'blue', 'blue', 'green', 'green', 'green', 'green', 'orange', 'orange', 'orange', 'orange', \n",
    "    'red', 'red', 'purple', 'cyan', 'cyan'\n",
    "]\n",
    "\n",
    "# 创建主图\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, model in enumerate(models):\n",
    "    ax.scatter(gflops[i], map_values[i], s=bubble_size[i], color=colors[i], alpha=0.6, edgecolors=\"k\", label=model if model not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 标注模型名称\n",
    "for i, model in enumerate(models):\n",
    "    ax.annotate(model, (gflops[i], map_values[i] - 1), fontsize=9, ha='center')\n",
    "\n",
    "# 画对比虚线，并在中间标注差值\n",
    "comparison_pairs = [\n",
    "    (\"RT-DETRv2\", \"MSAR-B\"),\n",
    "    (\"YOLOV8n\", \"MSAR-T\")\n",
    "]\n",
    "\n",
    "for model1, model2 in comparison_pairs:\n",
    "    i1, i2 = models.index(model1), models.index(model2)\n",
    "    gflops_diff = gflops[i2] - gflops[i1]\n",
    "    map_diff = map_values[i2] - map_values[i1]\n",
    "\n",
    "    if model1 == \"RT-DETRv2\" and model2 == \"MSAR-B\":\n",
    "        ax.plot([gflops[i1], gflops[i2]], [map_values[i1], map_values[i1]], linestyle='dotted', color='blue', alpha=0.7)\n",
    "        ax.plot([gflops[i2], gflops[i2]], [map_values[i1], map_values[i2]], linestyle='dotted', color='red', alpha=0.7)\n",
    "        \n",
    "        ax.text((gflops[i1] + gflops[i2]) / 2, map_values[i1] - 1, f\"ΔGFLOPs: {gflops_diff:.1f}\", color='blue', fontsize=10, ha='center')\n",
    "        ax.text(gflops[i2] + 1, (map_values[i1] + map_values[i2]) / 2, f\"ΔmAP: {map_diff:.1f}\", color='red', fontsize=10, ha='left')\n",
    "\n",
    "    elif model1 == \"YOLOV8n\" and model2 == \"MSAR-T\":\n",
    "        ax.plot([gflops[i1], gflops[i1]], [map_values[i1], map_values[i2]], linestyle='dotted', color='blue', alpha=0.7)\n",
    "        ax.plot([gflops[i1], gflops[i2]], [map_values[i2], map_values[i2]], linestyle='dotted', color='red', alpha=0.7)\n",
    "        \n",
    "        ax.text(gflops[i1] - 2, (map_values[i1] + map_values[i2]) / 2, f\"ΔmAP: {map_diff:.1f}\", color='blue', fontsize=10, ha='right')\n",
    "        ax.text((gflops[i1] + gflops[i2]) / 2, map_values[i2] + 1, f\"ΔGFLOPs: {gflops_diff:.1f}\", color='red', fontsize=10, ha='center')\n",
    "\n",
    "# 设定坐标轴标签和标题\n",
    "ax.set_xlabel(\"GFLOPs\")\n",
    "ax.set_ylabel(\"mAP\")\n",
    "ax.set_title(\"GFLOPs vs. mAP (Bubble Size Represents Model Parameters)\")\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义函数将数据坐标转换为 figure 归一化坐标\n",
    "def data_to_fig_coords(ax, x, y):\n",
    "    return ax.transData.transform((x, y))  # 将数据坐标转换为屏幕坐标\n",
    "\n",
    "def fig_to_axes_coords(ax, x, y):\n",
    "    inv = ax.transAxes.inverted()  # 获取 figure 归一化坐标\n",
    "    return inv.transform((x, y))  # 转换为 axes 坐标\n",
    "\n",
    "# 定义模型数据\n",
    "models = [\n",
    "    \"Faster R-CNN\", \"Cascade R-CNN\", \"YOLOV5n\", \"YOLOV8n\", \"YOLOV10n\", \"YOLOV11n\", \n",
    "    \"YOLOV5s\", \"YOLOV8s\", \"YOLOV10s\", \"YOLOV11s\", \"RT-DETR\", \"RT-DETRv2\", \"DINO\", \"MSAD-T\", \"MSAD-B\"\n",
    "]\n",
    "\n",
    "gflops = [91.3, 119.0, 7.1, 8.1, 8.4, 6.4, 23.8, 28.4, 24.4, 21.6, 130.5, 100.5, 119.0, 12.2, 47.8]\n",
    "map_values = [51.7, 47.9, 67.2, 74.2, 63.4, 68.8, 68.9, 79.9, 73.4, 76.1, 53.8, 64.0, 57.0, 76.3, 81.9]\n",
    "params = [41.7, 69.4, 2.5, 3.0, 2.7, 2.6, 9.1, 11.1, 8.0, 9.4, 42.7, 36.4, 47.5, 5.5, 20.7]\n",
    "\n",
    "# 归一化气泡大小\n",
    "bubble_size = np.array(params) * 10\n",
    "\n",
    "# 颜色区分不同算法\n",
    "colors = [\n",
    "    'blue', 'blue', 'green', 'green', 'green', 'green', 'orange', 'orange', 'orange', 'orange', \n",
    "    'red', 'red', 'purple', 'cyan', 'cyan'\n",
    "]\n",
    "\n",
    "# 创建主图\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, model in enumerate(models):\n",
    "    ax.scatter(gflops[i], map_values[i], s=bubble_size[i], color=colors[i], alpha=0.6, edgecolors=\"k\", label=model if model not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 标注模型名称\n",
    "for i, model in enumerate(models):\n",
    "    ax.annotate(model, (gflops[i], map_values[i] - 1), fontsize=9, ha='center')\n",
    "\n",
    "# 画对比虚线，并在中间标注差值\n",
    "comparison_pairs = [\n",
    "    (\"RT-DETRv2\", \"MSAD-B\"),\n",
    "    (\"YOLOV8n\", \"MSAD-T\")\n",
    "]\n",
    "\n",
    "for model1, model2 in comparison_pairs:\n",
    "    i1, i2 = models.index(model1), models.index(model2)\n",
    "    gflops_diff = gflops[i2] - gflops[i1]\n",
    "    map_diff = map_values[i2] - map_values[i1]\n",
    "\n",
    "    if model1 == \"RT-DETRv2\" and model2 == \"MSAD-B\":\n",
    "        ax.plot([gflops[i1], gflops[i2]], [map_values[i1], map_values[i1]], linestyle='dotted', color='blue', alpha=0.7)\n",
    "        ax.plot([gflops[i2], gflops[i2]], [map_values[i1], map_values[i2]], linestyle='dotted', color='red', alpha=0.7)\n",
    "        \n",
    "        ax.text((gflops[i1] + gflops[i2]) / 2, map_values[i1] - 1.2, f\"ΔGFLOPs: {np.abs(gflops_diff):.1f}\", color='blue', fontsize=10, ha='center')\n",
    "        ax.text(gflops[i2] + 1, (map_values[i1] + map_values[i2]) / 2, f\"ΔmAP: {map_diff:.1f}\", color='red', fontsize=10, ha='left')\n",
    "\n",
    "# 计算放大区域的边界\n",
    "i1, i2 = models.index(\"YOLOV8n\"), models.index(\"MSAD-T\")\n",
    "x_min, x_max = min(gflops[i1], gflops[i2]) - 1, max(gflops[i1], gflops[i2]) + 2\n",
    "y_min, y_max = min(map_values[i1], map_values[i2]) - 1.5, max(map_values[i1], map_values[i2]) + 1\n",
    "\n",
    "# 在主图上框选出放大区域\n",
    "ax.plot([x_min, x_max, x_max, x_min, x_min], [y_min, y_min, y_max, y_max, y_min], linestyle=\"dashed\", color=\"black\", alpha=0.4)\n",
    "\n",
    "# 计算主图框选区域的右上角和右下角（数据坐标系）\n",
    "ax.plot([x_max, 84.2], [y_max, 79.5], linestyle=\"dashed\", color=\"black\", alpha=0.4)\n",
    "ax.plot([x_max, 84.2], [y_min, 70], linestyle=\"dashed\", color=\"black\", alpha=0.4)\n",
    "\n",
    "# 添加放大图，并调整大小\n",
    "axins = fig.add_axes([0.6, 0.6, 0.2, 0.2])  \n",
    "\n",
    "# 只绘制YOLOV8n 和 MSAR-T\n",
    "axins.scatter(gflops[i1], map_values[i1], s=bubble_size[i1], color='green', alpha=0.6, edgecolors=\"k\", label=\"YOLOV8n\")\n",
    "axins.scatter(gflops[i2], map_values[i2], s=bubble_size[i2], color='cyan', alpha=0.6, edgecolors=\"k\", label=\"MSAR-T\")\n",
    "\n",
    "# 缩放放大图范围，使其与主图框选区域一致\n",
    "axins.set_xlim(x_min, x_max)\n",
    "axins.set_ylim(y_min, y_max)\n",
    "\n",
    "# 画虚线对比（先竖直后水平）\n",
    "axins.plot([gflops[i1], gflops[i1]], [map_values[i1], map_values[i2]], linestyle='dotted', color='red', alpha=0.7)\n",
    "axins.plot([gflops[i1], gflops[i2]], [map_values[i2], map_values[i2]], linestyle='dotted', color='blue', alpha=0.7)\n",
    "\n",
    "# 在放大图上标注差值\n",
    "axins.text(gflops[i1] + 2.2, (map_values[i1] + map_values[i2]) / 2 -0.2, f\"ΔmAP: {map_diff:.1f}\", color='red', fontsize=8, ha='right')\n",
    "axins.text((gflops[i1] + gflops[i2]) / 2, map_values[i2] + 0.2, f\"ΔGFLOPs: {gflops_diff:.1f}\", color='blue', fontsize=8, ha='center')\n",
    "\n",
    "# 放大图内部标题\n",
    "axins.set_title(\"YOLOV8n vs. MSAD-T\", fontsize=10)\n",
    "axins.set_xticks([])\n",
    "axins.set_yticks([])\n",
    "\n",
    "# 设定坐标轴标签和标题\n",
    "ax.set_xlabel(\"GFLOPs\")\n",
    "ax.set_ylabel(\"mAP(%)\")\n",
    "# ax.set_title(\"GFLOPs vs. mAP (Bubble Size Represents Model Parameters)\")\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义模型数据\n",
    "models = [\n",
    "    \"Faster R-CNN\", \"Cascade R-CNN\", \"YOLOV5n\", \"YOLOV8n\", \"YOLOV10n\", \"YOLOV11n\", \n",
    "    \"YOLOV5s\", \"YOLOV8s\", \"YOLOV10s\", \"YOLOV11s\", \"RT-DETR\", \"RT-DETRv2\", \"DINO\", \"MSAR-T\", \"MSAR-B\"\n",
    "]\n",
    "\n",
    "map_values = [51.7, 47.9, 67.2, 74.2, 63.4, 68.8, 68.9, 79.9, 73.4, 76.1, 53.8, 64.0, 57.0, 76.3, 81.9]\n",
    "fps_values = [55.6, 43.3, 158.7, 82.0, 238.1, 86.2, 156.3, 70.9, 188.7, 78.7, 59.9, 65.8, 55.6, 125.0, 64.1]\n",
    "gflops = [91.3, 119.0, 7.1, 8.1, 8.4, 6.4, 23.8, 28.4, 24.4, 21.6, 130.5, 100.5, 119.0, 12.2, 47.8]\n",
    "\n",
    "# 归一化气泡大小（基于 GFLOPs）\n",
    "bubble_size = np.array(gflops) * 5\n",
    "\n",
    "# 颜色区分不同算法\n",
    "colors = [\n",
    "    'blue', 'blue', 'green', 'green', 'green', 'green', 'orange', 'orange', 'orange', 'orange', \n",
    "    'red', 'red', 'purple', 'cyan', 'cyan'\n",
    "]\n",
    "\n",
    "# 创建主图\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, model in enumerate(models):\n",
    "    ax.scatter(fps_values[i], map_values[i], s=bubble_size[i], color=colors[i], alpha=0.6, edgecolors=\"k\", label=model if model not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 标注模型名称\n",
    "for i, model in enumerate(models):\n",
    "    ax.annotate(model, (fps_values[i], map_values[i] - 1), fontsize=9, ha='center')\n",
    "\n",
    "# 设定坐标轴标签和标题\n",
    "ax.set_xlabel(\"FPS\")\n",
    "ax.set_ylabel(\"mAP\")\n",
    "ax.set_title(\"FPS vs. mAP (Bubble Size Represents GFLOPs)\")\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define model data\n",
    "models = [\n",
    "    \"Faster R-CNN\", \"Cascade R-CNN\", \"YOLOV5n\", \"YOLOV8n\", \"YOLOV10n\", \"YOLOV11n\", \n",
    "    \"YOLOV5s\", \"YOLOV8s\", \"YOLOV10s\", \"YOLOV11s\", \"RT-DETR\", \"RT-DETRv2\", \"DINO\", \"MSAR-T\", \"MSAR-B\"\n",
    "]\n",
    "\n",
    "gflops = [91.3, 119.0, 7.1, 8.1, 8.4, 6.4, 23.8, 28.4, 24.4, 21.6, 130.5, 100.5, 119.0, 12.2, 47.8]\n",
    "map_values = [51.7, 47.9, 67.2, 74.2, 63.4, 68.8, 68.9, 79.9, 73.4, 76.1, 53.8, 64.0, 57.0, 76.3, 81.9]\n",
    "params = [41.7, 69.4, 2.5, 3.0, 2.7, 2.6, 9.1, 11.1, 8.0, 9.4, 42.7, 36.4, 47.5, 5.5, 20.7]\n",
    "\n",
    "# Normalize bubble sizes based on parameters (params M)\n",
    "bubble_size = np.array(params) * 10\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(gflops, map_values, s=bubble_size, alpha=0.6, edgecolors=\"k\")\n",
    "\n",
    "# Add annotations for each model (position below circles)\n",
    "for i, model in enumerate(models):\n",
    "    plt.annotate(model, (gflops[i], map_values[i] - 1), fontsize=9, ha='center')  # Shift text below\n",
    "\n",
    "# Add comparison arrows with value difference\n",
    "comparison_pairs = [\n",
    "    (\"RT-DETRv2\", \"MSAR-B\"),  # Comparing RT-DETRv2 and MSAR-B\n",
    "    (\"YOLOV8n\", \"MSAR-T\")     # Comparing YOLOV8n and MSAR-T\n",
    "]\n",
    "\n",
    "for model1, model2 in comparison_pairs:\n",
    "    i1, i2 = models.index(model1), models.index(model2)\n",
    "\n",
    "    # Compute differences\n",
    "    gflops_diff = np.abs(gflops[i2] - gflops[i1])\n",
    "    map_diff = map_values[i2] - map_values[i1]\n",
    "\n",
    "    # Draw horizontal arrow for GFLOPs difference\n",
    "    plt.arrow(\n",
    "        gflops[i1], map_values[i1],\n",
    "        gflops_diff, 0,\n",
    "        head_width=0.8, head_length=1, fc='blue', ec='blue', alpha=0.7, linestyle='dotted'\n",
    "    )\n",
    "    plt.text(\n",
    "        (gflops[i1] + gflops[i2]) / 2, map_values[i1] - 1.5,\n",
    "        f\"ΔGFLOPs: {gflops_diff:.1f}\", color='blue', fontsize=10, ha='center'\n",
    "    )\n",
    "\n",
    "    # Draw vertical arrow for mAP difference\n",
    "    plt.arrow(\n",
    "        gflops[i2], map_values[i1],\n",
    "        0, map_diff,\n",
    "        head_width=1, head_length=0.8, fc='red', ec='red', alpha=0.7, linestyle='dotted'\n",
    "    )\n",
    "    plt.text(\n",
    "        gflops[i2] + 2, (map_values[i1] + map_values[i2]) / 2,\n",
    "        f\"ΔmAP: {map_diff:.1f}\", color='red', fontsize=10, ha='left'\n",
    "    )\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"GFLOPs\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"GFLOPs vs. mAP (Bubble Size Represents Model Parameters)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 合并json文件\n",
    "import json\n",
    "\n",
    "# 需要合并的 JSON 文件\n",
    "files = [\"qwen_article_output.json\", \"qwen_book_output.json\", \"qwen_web_output.json\"]\n",
    "\n",
    "# 存储合并后的数据\n",
    "merged_data = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)  # 读取 JSON\n",
    "        if isinstance(data, list):\n",
    "            merged_data.extend(data)  # 合并列表\n",
    "        else:\n",
    "            merged_data.append(data)  # 如果是字典，作为列表项添加\n",
    "\n",
    "# 写入合并后的 JSON 文件\n",
    "with open(\"sft_output_all_250220.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"JSON 文件合并完成，结果已保存为 merged_output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 合并jsonl文件\n",
    "import json\n",
    "\n",
    "# 需要合并的 JSONL 文件\n",
    "# files = [\"mateinfo/articals-1112.jsonl\", \"mateinfo/books-1113.jsonl\", \"mateinfo/web_deduped-1114.jsonl\"]\n",
    "\n",
    "files = [\"outputs/sft_data/final/train_article_data.jsonl\", \"outputs/sft_data/final/train_book_data.jsonl\", \"outputs/sft_data/final/train_web_data.jsonl\"]\n",
    "\n",
    "# 目标合并后的文件\n",
    "output_file = \"outputs/sft_data/final/train_data.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:  # 逐行读取\n",
    "                outfile.write(line)  # 直接写入，不改变格式\n",
    "\n",
    "print(f\"JSONL 文件合并完成，结果已保存为 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# file_path = \"/home/wyp/project/forest/forestllm-main/qwen_article_output.json\"\n",
    "# file_path = \"/home/wyp/project/forest/forestllm-main/qwen_book_output.json\"\n",
    "# file_path = \"/home/wyp/project/forest/forestllm-main/qwen_web_output.json\"\n",
    "file_path = \"sft_output_all_250220.json\"  # 59576\n",
    "# 从文件中读取 JSON 数据\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# 打印 JSON 数据的长度\n",
    "print(len(json_data))  # 如果是数组，输出数组长度；如果是对象，输出键值对数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"outputs/sft_data/final/train_data.jsonl\"  # 替换为你的 JSONL 文件名 31162  4001  516  26645   59576 \n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    line_count = sum(1 for _ in f)\n",
    "\n",
    "print(f\"文件 {file_path} 共有 {line_count} 条数据\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# 文件路径\n",
    "file_path = \"/home/wyp/project/ForestLLM/outputs/article/qwen_article_output.json\"\n",
    "# \"/home/wyp/project/ForestLLM/outputs/0113/qwen_web_output.json\"\n",
    "\n",
    "\n",
    "# 查找重复 ID 的函数\n",
    "def find_duplicate_ids_with_consistency(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # 提取所有的 ID 和对应数据\n",
    "        id_map = defaultdict(list)\n",
    "        for entry in data:\n",
    "            if \"id\" in entry:\n",
    "                id_map[entry[\"id\"]].append(entry)\n",
    "\n",
    "        # 统计每个 ID 的出现次数\n",
    "        duplicates = {\n",
    "            id_: entries for id_, entries in id_map.items() if len(entries) > 1\n",
    "        }\n",
    "        duplicate_count = len(duplicates)\n",
    "\n",
    "        # 检查每组重复 ID 数据是否完全一致\n",
    "        consistency_results = {}\n",
    "        for id_, entries in duplicates.items():\n",
    "            # 使用第一条数据作为参考，逐条比对\n",
    "            reference_entry = json.dumps(entries[0], sort_keys=True)\n",
    "            all_consistent = all(\n",
    "                json.dumps(entry, sort_keys=True) == reference_entry\n",
    "                for entry in entries\n",
    "            )\n",
    "            consistency_results[id_] = {\n",
    "                \"count\": len(entries),\n",
    "                \"consistent\": all_consistent,\n",
    "            }\n",
    "\n",
    "        return consistency_results, duplicate_count\n",
    "    except Exception as e:\n",
    "        return str(e), 0\n",
    "\n",
    "\n",
    "# 执行检查\n",
    "consistency_results, duplicate_count = find_duplicate_ids_with_consistency(file_path)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"重复的 ID 总数: {duplicate_count}\")\n",
    "print(\"重复的 ID 检查结果:\")\n",
    "for id_, result in consistency_results.items():\n",
    "    status = \"一致\" if result[\"consistent\"] else \"不一致\"\n",
    "    print(f\"- ID: {id_}, 出现次数: {result['count']}, 数据是否一致: {status}\")\n",
    "print(f\"重复的 ID 总数: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def split_mixed_jsonl(input_file, train_output_file, eval_output_file, batch_size=1000):\n",
    "    \"\"\"\n",
    "    将混合的 JSONL 文件拆分成训练数据 (train) 和 评测数据 (eval)\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    eval_data = []\n",
    "\n",
    "    # 读取原始 JSONL 文件\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data = json.loads(line.strip())  # 解析 JSON\n",
    "                if \"messages\" in data:  # **训练数据**\n",
    "                    train_data.append(data)\n",
    "                elif \"history\" in data:  # **评测数据**\n",
    "                    eval_data.append(data)\n",
    "                else:\n",
    "                    print(f\"⚠️ 未知数据格式，跳过：{data}\")  # 遇到无法解析的数据，跳过\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"❌ JSON 解析失败，跳过：{line.strip()}\")\n",
    "\n",
    "            # **批量写入，减少 I/O 操作**\n",
    "            if len(train_data) >= batch_size:\n",
    "                with open(train_output_file, \"a\", encoding=\"utf-8\") as train_f:\n",
    "                    for entry in train_data:\n",
    "                        train_f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "                train_data = []\n",
    "\n",
    "            if len(eval_data) >= batch_size:\n",
    "                with open(eval_output_file, \"a\", encoding=\"utf-8\") as eval_f:\n",
    "                    for entry in eval_data:\n",
    "                        eval_f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "                eval_data = []\n",
    "\n",
    "    # **写入剩余数据**\n",
    "    if train_data:\n",
    "        with open(train_output_file, \"a\", encoding=\"utf-8\") as train_f:\n",
    "            for entry in train_data:\n",
    "                train_f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    if eval_data:\n",
    "        with open(eval_output_file, \"a\", encoding=\"utf-8\") as eval_f:\n",
    "            for entry in eval_data:\n",
    "                eval_f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ 训练数据已保存到 {train_output_file}\")\n",
    "    print(f\"✅ 评测数据已保存到 {eval_output_file}\")\n",
    "\n",
    "# 示例调用\n",
    "split_mixed_jsonl(\"/home/wyp/project/ForestLLM/data_sft/eval_general_qa_readable.jsonl\", \"/home/wyp/project/ForestLLM/data_sft/train_general_qa.jsonl\", \"/home/wyp/project/ForestLLM/data_sft/eval_general_qa.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 数据提取自表格\n",
    "benchmarks = [\n",
    "    \"MMLU\", \"MMLU-Redux\", \"MMLU-Pro\", \"DROP\", \"IF-Eval\",\n",
    "    \"GPOA Diamond\", \"SimpleQA\", \"FRAMES\", \"AlpacaEval2.0\", \"ArenaHard\",\n",
    "    \"LiveCodeBench\", \"Codeforces\", \"SWE Verified\", \"Aider-Polyglot\",\n",
    "    \"AIME 2024\", \"MATH-500\", \"CNMO 2024\",\n",
    "    \"CLUEWSC\", \"C-Eval\", \"C-SimpleQA\"\n",
    "]\n",
    "\n",
    "models = [\"Claude-3.5-Sonnet\", \"GPT-4o\", \"DeepSeek V3\", \"OpenAI o1-mini\", \"OpenAI o1-1217\", \"DeepSeek R1\"]\n",
    "\n",
    "data = np.array([\n",
    "    [88.3, 87.2, 88.5, 85.2, 91.8, 90.8],  # MMLU\n",
    "    [88.9, 88.0, 89.1, 86.7, 0, 92.9],  # MMLU-Redux\n",
    "    [78.0, 72.6, 75.9, 80.3, 0, 84.0],  # MMLU-Pro\n",
    "    [88.3, 83.7, 91.6, 83.9, 90.2, 92.2],  # DROP\n",
    "    [86.5, 84.3, 86.1, 84.8, 0, 83.3],  # IF-Eval\n",
    "    [65.0, 49.9, 59.1, 60.0, 75.7, 71.5],  # GPOA Diamond\n",
    "    [28.4, 38.2, 24.9, 7.0, 47.0, 30.1],  # SimpleQA\n",
    "    [72.5, 80.5, 73.3, 76.9, 0, 82.5],  # FRAMES\n",
    "    [52.0, 51.1, 70.0, 57.8, 0, 87.6],  # AlpacaEval2.0\n",
    "    [85.2, 80.4, 85.5, 92.0, 0, 92.3],  # ArenaHard\n",
    "    [38.9, 32.9, 36.0, 53.8, 63.4, 65.9],  # LiveCodeBench\n",
    "    [20.3, 23.6, 58.7, 93.4, 96.6, 96.3],  # Codeforces\n",
    "    [50.8, 38.8, 42.0, 41.6, 48.9, 49.2],  # SWE Verified\n",
    "    [45.3, 16.0, 49.6, 32.9, 61.7, 53.3],  # Aider-Polyglot\n",
    "    [16.0, 9.3, 39.2, 63.6, 79.2, 79.8],   # AIME 2024\n",
    "    [78.3, 74.6, 90.2, 90.0, 96.4, 97.3],  # MATH-500\n",
    "    [13.1, 10.8, 43.2, 67.6, 0, 78.8],  # CNMO 2024\n",
    "    [85.4, 87.9, 90.9, 89.9, 0, 92.8],  # CLUEWSC\n",
    "    [76.7, 76.0, 86.5, 68.9, 0, 91.8],  # C-Eval\n",
    "    [55.4, 58.7, 68.0, 40.3, 0, 63.7]   # C-SimpleQA\n",
    "])\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data, index=benchmarks, columns=models)\n",
    "\n",
    "# 绘制多个柱状图\n",
    "num_benchmarks = len(benchmarks)\n",
    "num_models = len(models)\n",
    "x = np.arange(num_benchmarks)\n",
    "\n",
    "# 设置颜色\n",
    "colors = [\"#7ea8be\", \"#4a6fa5\", \"#1f4e79\", \"#7ea8be\", \"#4a6fa5\", \"#1f4e79\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(num_models):\n",
    "    plt.bar(x + i * 0.12, df.iloc[:, i], width=0.12, label=models[i], color=colors[i])\n",
    "\n",
    "plt.xticks(x + 0.3, benchmarks, rotation=90)\n",
    "plt.ylabel(\"Score (%)\")\n",
    "plt.title(\"Benchmark Comparison Across AI Models\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 数据提取自表格\n",
    "benchmarks = [\n",
    "    \"MMLU\", \"MMLU-Redux\", \"MMLU-Pro\", \"DROP\", \"IF-Eval\",\n",
    "    \"GPOA Diamond\", \"SimpleQA\", \"FRAMES\", \"AlpacaEval2.0\", \"ArenaHard\",\n",
    "    \"LiveCodeBench\", \"Codeforces\", \"SWE Verified\", \"Aider-Polyglot\",\n",
    "    \"AIME 2024\", \"MATH-500\", \"CNMO 2024\",\n",
    "    \"CLUEWSC\", \"C-Eval\", \"C-SimpleQA\"\n",
    "]\n",
    "\n",
    "models = [\"Claude-3.5-Sonnet\", \"GPT-4o\", \"DeepSeek V3\", \"OpenAI o1-mini\", \"OpenAI o1-1217\", \"DeepSeek R1\"]\n",
    "\n",
    "data = np.array([\n",
    "    [88.3, 87.2, 88.5, 85.2, 91.8, 90.8],  # MMLU\n",
    "    [88.9, 88.0, 89.1, 86.7, 0, 92.9],  # MMLU-Redux\n",
    "    [78.0, 72.6, 75.9, 80.3, 0, 84.0],  # MMLU-Pro\n",
    "    [88.3, 83.7, 91.6, 83.9, 90.2, 92.2],  # DROP\n",
    "    [86.5, 84.3, 86.1, 84.8, 0, 83.3],  # IF-Eval\n",
    "    [65.0, 49.9, 59.1, 60.0, 75.7, 71.5],  # GPOA Diamond\n",
    "    [28.4, 38.2, 24.9, 7.0, 47.0, 30.1],  # SimpleQA\n",
    "    [72.5, 80.5, 73.3, 76.9, 0, 82.5],  # FRAMES\n",
    "    [52.0, 51.1, 70.0, 57.8, 0, 87.6],  # AlpacaEval2.0\n",
    "    [85.2, 80.4, 85.5, 92.0, 0, 92.3],  # ArenaHard\n",
    "    [38.9, 32.9, 36.0, 53.8, 63.4, 65.9],  # LiveCodeBench\n",
    "    [20.3, 23.6, 58.7, 93.4, 96.6, 96.3],  # Codeforces\n",
    "    [50.8, 38.8, 42.0, 41.6, 48.9, 49.2],  # SWE Verified\n",
    "    [45.3, 16.0, 49.6, 32.9, 61.7, 53.3],  # Aider-Polyglot\n",
    "    [16.0, 9.3, 39.2, 63.6, 79.2, 79.8],   # AIME 2024\n",
    "    [78.3, 74.6, 90.2, 90.0, 96.4, 97.3],  # MATH-500\n",
    "    [13.1, 10.8, 43.2, 67.6, 0, 78.8],  # CNMO 2024\n",
    "    [85.4, 87.9, 90.9, 89.9, 0, 92.8],  # CLUEWSC\n",
    "    [76.7, 76.0, 86.5, 68.9, 0, 91.8],  # C-Eval\n",
    "    [55.4, 58.7, 68.0, 40.3, 0, 63.7]   # C-SimpleQA\n",
    "])\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data, index=benchmarks, columns=models)\n",
    "\n",
    "# 绘制多个柱状图\n",
    "num_benchmarks = len(benchmarks)\n",
    "num_models = len(models)\n",
    "x = np.arange(num_benchmarks)\n",
    "\n",
    "# 设置颜色\n",
    "colors = [\"#7ea8be\", \"#4a6fa5\", \"#1f4e79\", \"#7ea8be\", \"#4a6fa5\", \"#FFA500\"]\n",
    "\n",
    "# 调整图表尺寸\n",
    "plt.figure(figsize=(18, 12))  # 增大图表尺寸\n",
    "\n",
    "for i in range(num_models):\n",
    "    plt.bar(x + i * 0.12, df.iloc[:, i], width=0.12, label=models[i], color=colors[i])\n",
    "\n",
    "plt.xticks(x + 0.3, benchmarks, rotation=90, fontsize=12)  # 调整 x 轴字体大小\n",
    "plt.yticks(fontsize=12)  # 调整 y 轴字体大小\n",
    "plt.ylabel(\"Score (%)\", fontsize=14)  # 调整 y 轴标签字体\n",
    "plt.title(\"Benchmark Comparison Across AI Models\", fontsize=18)  # 增大标题字体\n",
    "plt.legend(fontsize=12)  # 增大图例字体\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 数据提取自表格\n",
    "benchmarks = [\n",
    "    \"MMLU\", \"MMLU-Redux\", \"MMLU-Pro\", \"DROP\", \"IF-Eval\",\n",
    "    \"GPOA Diamond\", \"SimpleQA\", \"FRAMES\", \"AlpacaEval2.0\", \"ArenaHard\",\n",
    "    \"LiveCodeBench\", \"Codeforces\", \"SWE Verified\", \"Aider-Polyglot\",\n",
    "    \"AIME 2024\", \"MATH-500\", \"CNMO 2024\",\n",
    "    \"CLUEWSC\", \"C-Eval\", \"C-SimpleQA\"\n",
    "]\n",
    "\n",
    "models = [\"Claude-3.5-Sonnet\", \"GPT-4o\", \"DeepSeek V3\", \"OpenAI o1-mini\", \"OpenAI o1-1217\", \"DeepSeek R1\"]\n",
    "\n",
    "data = np.array([\n",
    "    [88.3, 87.2, 88.5, 85.2, 91.8, 90.8],  # MMLU\n",
    "    [88.9, 88.0, 89.1, 86.7, 0, 92.9],  # MMLU-Redux\n",
    "    [78.0, 72.6, 75.9, 80.3, 0, 84.0],  # MMLU-Pro\n",
    "    [88.3, 83.7, 91.6, 83.9, 90.2, 92.2],  # DROP\n",
    "    [86.5, 84.3, 86.1, 84.8, 0, 83.3],  # IF-Eval\n",
    "    [65.0, 49.9, 59.1, 60.0, 75.7, 71.5],  # GPOA Diamond\n",
    "    [28.4, 38.2, 24.9, 7.0, 47.0, 30.1],  # SimpleQA\n",
    "    [72.5, 80.5, 73.3, 76.9, 0, 82.5],  # FRAMES\n",
    "    [52.0, 51.1, 70.0, 57.8, 0, 87.6],  # AlpacaEval2.0\n",
    "    [85.2, 80.4, 85.5, 92.0, 0, 92.3],  # ArenaHard\n",
    "    [38.9, 32.9, 36.0, 53.8, 63.4, 65.9],  # LiveCodeBench\n",
    "    [20.3, 23.6, 58.7, 93.4, 96.6, 96.3],  # Codeforces\n",
    "    [50.8, 38.8, 42.0, 41.6, 48.9, 49.2],  # SWE Verified\n",
    "    [45.3, 16.0, 49.6, 32.9, 61.7, 53.3],  # Aider-Polyglot\n",
    "    [16.0, 9.3, 39.2, 63.6, 79.2, 79.8],   # AIME 2024\n",
    "    [78.3, 74.6, 90.2, 90.0, 96.4, 97.3],  # MATH-500\n",
    "    [13.1, 10.8, 43.2, 67.6, 0, 78.8],  # CNMO 2024\n",
    "    [85.4, 87.9, 90.9, 89.9, 0, 92.8],  # CLUEWSC\n",
    "    [76.7, 76.0, 86.5, 68.9, 0, 91.8],  # C-Eval\n",
    "    [55.4, 58.7, 68.0, 40.3, 0, 63.7]   # C-SimpleQA\n",
    "])\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data, index=benchmarks, columns=models)\n",
    "\n",
    "# 逐个基准测试绘制单独的柱状图\n",
    "for i, benchmark in enumerate(benchmarks):\n",
    "    plt.figure(figsize=(6, 4))  # 设置单个图表大小\n",
    "    \n",
    "    # 获取当前基准测试的数据\n",
    "    scores = df.iloc[i, :]\n",
    "    \n",
    "    # 颜色风格（淡紫色 & 深紫色），最高分用深紫色，其余用淡紫色\n",
    "    # colors = [\"#A7A2FF\" if score < max(scores) else \"#4A3DA3\" for score in scores]\n",
    "    colors = [\"#A7A2FF\", \"#A7A2FF\", \"#A7A2FF\", \"#A7A2FF\", \"#A7A2FF\", \"#4A3DA3\"]\n",
    "    # 绘制柱状图\n",
    "    bars = plt.bar(models, scores, color=colors)\n",
    "\n",
    "    # 在柱状图上方标注数值\n",
    "    for bar, score in zip(bars, scores):\n",
    "        if score == 0:\n",
    "            pass\n",
    "        else:\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, f'{score:.1f}%',\n",
    "                    ha='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "    # 图表标题\n",
    "    plt.title(benchmark, fontsize=12)\n",
    "\n",
    "    # y 轴标签\n",
    "    plt.ylabel(\"Score (%)\", fontsize=8)\n",
    "    \n",
    "    # 隐藏 x 轴标签，仅展示模型名\n",
    "    plt.xticks(rotation=20, ha='right', fontsize=8)\n",
    "\n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 显示图表\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 修正后的基准列表（与 data 行数匹配）\n",
    "benchmarks = [\n",
    "    \"MMLU\", \"MMLU-Redux\", \"MMLU-Pro\", \"FRAMES\", \"AlpacaEval2.0\",\n",
    "    \"ArenaHard\", \"LiveCodeBench\", \"MATH-500\", \"CNMO 2024\", \"C-Eval\"\n",
    "]\n",
    "\n",
    "# 模型列表\n",
    "models = [\"Claude-3.5-Sonnet\", \"GPT-4o\", \"DeepSeek V3\", \"OpenAI o1-mini\", \"OpenAI o1-1217\", \"DeepSeek R1\"]\n",
    "\n",
    "# 10 行数据\n",
    "data = np.array([\n",
    "    [88.3, 87.2, 88.5, 85.2, 91.8, 90.8],  # MMLU\n",
    "    [88.9, 88.0, 89.1, 86.7, 0, 92.9],  # MMLU-Redux\n",
    "    [78.0, 72.6, 75.9, 80.3, 0, 84.0],  # MMLU-Pro\n",
    "    [72.5, 80.5, 73.3, 76.9, 0, 82.5],  # FRAMES\n",
    "    [52.0, 51.1, 70.0, 57.8, 0, 87.6],  # AlpacaEval2.0\n",
    "    [85.2, 80.4, 85.5, 92.0, 0, 92.3],  # ArenaHard\n",
    "    [38.9, 32.9, 36.0, 53.8, 63.4, 65.9],  # LiveCodeBench\n",
    "    [78.3, 74.6, 90.2, 90.0, 96.4, 97.3],  # MATH-500\n",
    "    [13.1, 10.8, 43.2, 67.6, 0, 78.8],  # CNMO 2024\n",
    "    [76.7, 76.0, 86.5, 68.9, 0, 91.8]   # C-Eval\n",
    "])\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data, index=benchmarks, columns=models)\n",
    "\n",
    "# 设置子图布局（2行5列）\n",
    "num_rows, num_cols = 2, 5\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 10))\n",
    "fig.suptitle(\"Benchmark Comparison Across AI Models\", fontsize=20)\n",
    "\n",
    "# 遍历 benchmarks 绘制子图\n",
    "for i, (benchmark, ax) in enumerate(zip(benchmarks, axes.flatten())):\n",
    "    scores = df.iloc[i, :]\n",
    "    \n",
    "    # 颜色风格（最高分用深紫色）\n",
    "    colors = [\"#A7A2FF\" if score < max(scores) else \"#4A3DA3\" for score in scores]\n",
    "\n",
    "    # 绘制柱状图\n",
    "    bars = ax.bar(models, scores, color=colors)\n",
    "\n",
    "    # 在柱状图上方标注数值\n",
    "    for bar, score in zip(bars, scores):\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, f'{score:.1f}%',\n",
    "                ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # 设置子图标题\n",
    "    ax.set_title(benchmark, fontsize=12)\n",
    "    \n",
    "    # 确保 x 轴刻度正确\n",
    "    ax.set_xticks(range(len(models)))\n",
    "    ax.set_xticklabels(models, rotation=20, ha='right', fontsize=8)\n",
    "\n",
    "    # 统一 y 轴范围\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# 1. 读取嵌入数据\n",
    "original_embeddings = np.load(\"outputs/emb_data/llama_embeddings_original.npy\")  # 原始数据嵌入\n",
    "generated_embeddings = np.load(\"outputs/emb_data/llama_embeddings_generated_response.npy\")  # 生成数据嵌入\n",
    "\n",
    "# 2. 给数据添加标签\n",
    "original_labels = [\"original\"] * len(original_embeddings)\n",
    "generated_labels = [\"generated\"] * len(generated_embeddings)\n",
    "\n",
    "# 3. 合并数据\n",
    "all_embeddings = np.vstack((original_embeddings, generated_embeddings))\n",
    "all_labels = np.array(original_labels + generated_labels)\n",
    "\n",
    "# 4. 选择降维方法 (可选 PCA, t-SNE, UMAP)\n",
    "def reduce_dimension(embeddings, method=\"umap\"):\n",
    "    if method == \"pca\":\n",
    "        reducer = PCA(n_components=2)\n",
    "    elif method == \"tsne\":\n",
    "        reducer = TSNE(n_components=2, perplexity=50, random_state=42)\n",
    "    elif method == \"umap\":\n",
    "        reducer = umap.UMAP(n_components=2, n_neighbors=50, min_dist=0.1, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Method should be 'pca', 'tsne', or 'umap'\")\n",
    "    \n",
    "    return reducer.fit_transform(embeddings)\n",
    "\n",
    "# 5. 进行降维\n",
    "low_dim_embeddings = reduce_dimension(all_embeddings, method=\"umap\")\n",
    "\n",
    "# 6. 绘制可视化\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=low_dim_embeddings[:, 0], y=low_dim_embeddings[:, 1], hue=all_labels, alpha=0.7)\n",
    "plt.title(\"Embedding Visualization (UMAP)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.legend(title=\"Data Type\", loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 3D 降维\n",
    "low_dim_embeddings_3d = umap.UMAP(n_components=3, random_state=42).fit_transform(all_embeddings)\n",
    "\n",
    "# 画 3D 图\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "scatter = ax.scatter(low_dim_embeddings_3d[:, 0], low_dim_embeddings_3d[:, 1], low_dim_embeddings_3d[:, 2], c=(all_labels == \"generated\"), cmap=\"coolwarm\", alpha=0.7)\n",
    "ax.set_title(\"3D Embedding Visualization (UMAP)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# 1. 读取嵌入数据\n",
    "original_embeddings = np.load(\"outputs/emb_data/llama_embeddings_original.npy\")  # 原始数据嵌入\n",
    "generated_response_embeddings = np.load(\"outputs/emb_data/llama_embeddings_generated_response.npy\")  # 生成数据嵌入\n",
    "generated_knowledge_embeddings = np.load(\"outputs/emb_data/llama_embeddings_generated_knowledge.npy\")  # 知识点嵌入\n",
    "\n",
    "# 2. 给数据添加标签\n",
    "original_labels = [\"original\"] * len(original_embeddings)\n",
    "generated_response_labels = [\"generated_response\"] * len(generated_response_embeddings)\n",
    "generated_knowledge_labels = [\"generated_knowledge\"] * len(generated_knowledge_embeddings)\n",
    "\n",
    "# 3. 合并数据\n",
    "all_embeddings = np.vstack((original_embeddings, generated_response_embeddings, generated_knowledge_embeddings))\n",
    "all_labels = np.array(original_labels + generated_response_labels + generated_knowledge_labels)\n",
    "\n",
    "# 4. 先用 PCA 降到 256 维\n",
    "print(\"🔄 Applying PCA (4096 → 256) ...\")\n",
    "pca_256 = PCA(n_components=256, random_state=42)\n",
    "pca_256_embeddings = pca_256.fit_transform(all_embeddings)\n",
    "\n",
    "# 6. 进行 UMAP 降到 2 维\n",
    "print(\"🔄 Applying UMAP (50 → 2) ...\")\n",
    "umap_reducer = umap.UMAP(n_components=2, n_neighbors=150, min_dist=0.05, random_state=42)\n",
    "low_dim_embeddings = umap_reducer.fit_transform(pca_256_embeddings)\n",
    "\n",
    "# 7. 绘制可视化\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=low_dim_embeddings[:, 0], y=low_dim_embeddings[:, 1], hue=all_labels, alpha=0.7, palette=\"Set1\")\n",
    "plt.title(\"Embedding Visualization (UMAP)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.legend(title=\"Data Type\", loc=\"best\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
