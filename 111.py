import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cuml.umap as cuml_umap  # GPU ç‰ˆ UMAP
from cuml.decomposition import PCA  # GPU ç‰ˆ PCA
from sklearn.metrics.pairwise import cosine_similarity
import os

# 1. è¯»å–åµŒå…¥æ•°æ®ï¼ˆåªè®¡ç®—ç”Ÿæˆæ•°æ®çš„åˆ†å¸ƒï¼‰
original_embeddings = np.load("outputs/emb_data/bert/llama_embeddings_original_text.npy")  
generated_response_embeddings = np.load("outputs/emb_data/bert/llama_embeddings_generated_response.npy")  
generated_knowledge_embeddings = np.load("outputs/emb_data/bert/llama_embeddings_generated_knowledge.npy")  

# 2. è®¡ç®—â€œç”Ÿæˆæ•°æ®â€ä¸â€œåŸå§‹æ•°æ®â€çš„ç›¸ä¼¼æ€§ï¼ˆCosine Similarityï¼‰
print("ğŸ”„ Computing Cosine Similarity with Original Data (GPU)...")
response_similarity = cosine_similarity(generated_response_embeddings, original_embeddings)  
knowledge_similarity = cosine_similarity(generated_knowledge_embeddings, original_embeddings)

# 3. è·å–æœ€é«˜ç›¸ä¼¼åº¦ï¼ˆå–ä¸æœ€ç›¸ä¼¼çš„åŸå§‹æ•°æ®çš„ç›¸ä¼¼åº¦ï¼‰
max_response_similarity = np.max(response_similarity, axis=1)
max_knowledge_similarity = np.max(knowledge_similarity, axis=1)

# 4. è®¡ç®— Sequence Identity to Trainingï¼ˆè½¬æ¢ä¸º 0-100%ï¼‰
sequence_identity = np.concatenate((max_response_similarity, max_knowledge_similarity)) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”

# 5. **åˆå¹¶â€œç”Ÿæˆæ•°æ®â€åµŒå…¥**
generated_embeddings = np.vstack((generated_response_embeddings, generated_knowledge_embeddings))
generated_labels = np.array(["generated_response"] * len(generated_response_embeddings) + 
                            ["generated_knowledge"] * len(generated_knowledge_embeddings))

# 6. **ä½¿ç”¨ GPU ç‰ˆ PCA é¢„é™ç»´ï¼ˆ4096D â†’ 50Dï¼‰**
pca_path = "outputs/emb_data/reduced_pca_50_generated.npy"
if os.path.exists(pca_path):
    print("âœ… Loading PCA-reduced data from file...")
    pca_50_embeddings = np.load(pca_path)
else:
    print("ğŸ”„ Applying GPU PCA (4096 â†’ 50) ...")
    pca = PCA(n_components=50, random_state=42)
    pca_50_embeddings = pca.fit_transform(generated_embeddings)
    np.save(pca_path, pca_50_embeddings)
    print(f"âœ… PCA embeddings saved to {pca_path}")

# 7. **ä½¿ç”¨ GPU åŠ é€Ÿ UMAP é™ç»´**
umap_path = "outputs/emb_data/reduced_umap_2d_generated.npy"
if os.path.exists(umap_path):
    print("âœ… Loading UMAP-reduced embeddings from file...")
    low_dim_embeddings = np.load(umap_path)
else:
    print("ğŸ”„ Applying GPU UMAP on PCA-reduced data ...")
    umap_reducer = cuml_umap.UMAP(n_components=2, metric="cosine", n_neighbors=15, min_dist=0.3, random_state=42)
    low_dim_embeddings = umap_reducer.fit_transform(pca_50_embeddings)
    np.save(umap_path, low_dim_embeddings)
    print(f"âœ… UMAP embeddings saved to {umap_path}")

# 8. **å®šä¹‰é¢œè‰²æ˜ å°„ï¼ˆæ¸å˜è‰²ï¼ŒåŸºäºç›¸ä¼¼åº¦ï¼‰**
import matplotlib.colors as mcolors
cmap = mcolors.LinearSegmentedColormap.from_list("custom_cmap", [
    (100/255, 125/255, 125/255),  # ä½ç›¸ä¼¼åº¦ï¼ˆæ·±è‰²ï¼‰
    (160/255, 200/255, 180/255)   # é«˜ç›¸ä¼¼åº¦ï¼ˆäº®è‰²ï¼‰
])

# 9. **ç»˜åˆ¶å¯è§†åŒ–**
plt.figure(figsize=(10, 6))
sc = plt.scatter(
    low_dim_embeddings[:, 0],  
    low_dim_embeddings[:, 1],  
    c=sequence_identity,  # é¢œè‰²åŸºäºç›¸ä¼¼åº¦
    cmap=cmap,  
    alpha=0.7,  
    s=30,  
    edgecolors="black"
)

# 10. **æ·»åŠ é¢œè‰²æ¡ï¼ˆColorbarï¼‰**
cbar = plt.colorbar(sc)
cbar.set_label("% Sequence Identity to Training")

plt.title("Generated Data UMAP (Colored by Similarity to Training Data)")
plt.xlabel("Dimension 1")
plt.ylabel("Dimension 2")

# **ä¿å­˜å›¾ç‰‡**
img_path = "outputs/emb_data/embedding_umap_generated_similarity_gpu.png"
plt.savefig(img_path, dpi=300)
print(f"ğŸ“¸ Visualization saved as {img_path}")

# plt.show()
