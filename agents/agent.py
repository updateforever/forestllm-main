import json
from utils.global_methods import *
import re
from utils.toolkit import *
from prompts import *


class BaseAgent:
    """AgentåŸºç¡€ç±»ï¼Œä¸ºæ‰€æœ‰å­Agentæä¾›é€šç”¨æ¥å£å’ŒåŸºæœ¬åŠŸèƒ½"""

    def __init__(self, name="BaseAgent", model="qwen"):
        self.name = name
        self.feedback_history = []  # ç”¨äºå­˜å‚¨è¯„ä¼°åé¦ˆ
        self.model = model

    def load_prompts(self, prompt_file):
        """åŠ è½½ prompt æ–‡ä»¶"""
        with open(prompt_file, "r", encoding="utf-8") as f:
            return json.load(f)

    def receive_feedback(self, feedback):
        """æ¥å—è¯„ä¼°åé¦ˆçš„é€šç”¨æ–¹æ³•"""
        self.feedback_history.append(feedback)
        print(f"{self.name} æ”¶åˆ°åé¦ˆ: {feedback}")

    def generate_response(self, input_data):
        """ç”Ÿæˆå“åº”çš„é€šç”¨æ–¹æ³•ï¼Œå…·ä½“é€»è¾‘åœ¨å­ç±»ä¸­å®ç°"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°è¯¥æ–¹æ³•")


class QuestionSetter(BaseAgent):
    """å‡ºé¢˜äººAgentï¼Œç”Ÿæˆå„ç±»é¢˜å‹çš„é—®é¢˜å’Œæ ‡å‡†ç­”æ¡ˆ"""

    def __init__(self, model="qwen"):
        super().__init__(name="QuestionSetter", model=model)
        from prompts.question_prompts import QUESTION_PROMPTS_CN

        self.prompts = QUESTION_PROMPTS_CN

    def generate_response(self, input_data, data_class):
        """ç”Ÿæˆå®Œæ•´çš„è¯•å·ç»“æ„"""
        # æ­¥éª¤1: ä»è¾“å…¥ä¸­ç½—åˆ—çŸ¥è¯†ç‚¹å¹¶è¿›è¡Œå¤æ‚åº¦åˆ†æ
        knowledge_points = self.extract_knowledge_points(input_data, data_class)

        # æ­¥éª¤2: æ ¹æ®çŸ¥è¯†ç‚¹çš„éš¾åº¦åˆ†é…é¢˜å‹
        question_set = []
        for point, difficulty, original_question in knowledge_points:
            question_set.extend(
                self.generate_questions_for_point(point, original_question, difficulty, input_data)
            )

        return question_set

    def extract_knowledge_points(self, text, data_class):
        """æ ¹æ®æ•°æ®ç±»åˆ«ä»æ–‡æœ¬ä¸­æå–çŸ¥è¯†ç‚¹å¹¶è¯„ä¼°éš¾åº¦"""
        prompt_template = self.prompts[f"knowledge_extraction_{data_class}"]

        # æ„å»º prompt
        prompt = prompt_template.format(text=text, length=len(text), q_num=len(text)/500)

        # è°ƒç”¨å¤§æ¨¡å‹ç”ŸæˆçŸ¥è¯†ç‚¹
        response = run_agent(prompt, model=self.model, num_gen=1, temperature=1)

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»é™¤æ ¼å¼æ ‡è®°ï¼Œå¦‚ ```json å’Œ ```
        json_content = re.sub(r"```(?:json)?|```", "", response.strip())

        # è§£æç”Ÿæˆçš„ JSON æ ¼å¼çš„çŸ¥è¯†ç‚¹
        try:
            knowledge_points = json.loads(json_content)
            results = []
            for item in knowledge_points:
                for _, inner in item.items():  # éå†å¤–å±‚å”¯ä¸€çš„ key
                    results.append((inner["knowledge"], inner["difficulty"], inner['question']))
            return results
            # return [(kp["knowledge"], kp["difficulty"]) for kp in knowledge_points]
        except json.JSONDecodeError:
            print("JSON è§£æé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç”Ÿæˆçš„å†…å®¹æ ¼å¼--æå–çŸ¥è¯†ç‚¹å¹¶è¯„ä¼°éš¾åº¦")
            return []

    def generate_questions_for_point(self, knowledge_point, original_question, difficulty, full_text):
        """æ ¹æ®çŸ¥è¯†ç‚¹å’Œéš¾åº¦ç”Ÿæˆé€‚åˆçš„å¤šç§é¢˜å‹"""
        # æ ¹æ®éš¾åº¦é€‰æ‹©é€‚åˆçš„é¢˜å‹
        if difficulty == "simple" or difficulty == "ç®€å•":
            question_types = ["multiple_choice"]
        elif difficulty == "medium" or difficulty == "ä¸­ç­‰":
            question_types = ["short_answer"]
        elif difficulty == "complex" or difficulty == "å›°éš¾":
            question_types = ["open_discussion"]
        else:
            raise ValueError("æœªçŸ¥éš¾åº¦çº§åˆ«")

        questions = []

        for q_type in question_types:
            # ä» prompts ä¸­è·å–æŒ‡å®šé¢˜å‹çš„ prompt æ¨¡æ¿
            prompt_template = self.prompts[f"{q_type}"]

            prompt = prompt_template.format(
                full_text=full_text,
                knowledge_point=knowledge_point,
                original_question=original_question,
            )

            # è°ƒç”¨ run_chatgpt å‡½æ•°ç”Ÿæˆé—®é¢˜å’Œç­”æ¡ˆ
            response = run_agent(prompt, model=self.model, num_gen=1, temperature=0.7)

            # é»˜è®¤å­˜ response
            record = {
                "knowledge": knowledge_point,
                "difficulty": difficulty,
                "question_type": q_type,
            }
            response = re.sub(r"```(?:json)?|```", "", response.strip())
            parsed = json.loads(response)
            # ğŸ”¸ å¦‚æœæ˜¯ multiple_choiceï¼Œåˆ™å°è¯•è§£æ JSONï¼Œå¹¶æå–ä¸º CSV æ ¼å¼å­—æ®µ
            if q_type == "multiple_choice":
                # å®‰å…¨è·å–é€‰é¡¹ï¼Œè¡¥é½åˆ° 4 ä¸ª
                options = parsed.get("options", [])
                options = (options + ["", "", "", ""])[:4]

                # æ¸…æ´—å­—æ®µï¼Œå¤„ç†é€—å·è½¬ä¹‰
                question_text = parsed.get("question", "").replace(",", "ï¼Œ")
                answer_letter = parsed.get("answer", "").strip().upper()

                # æ„é€  CSV è¡Œå­—ç¬¦ä¸²ï¼ˆå­—æ®µé¡ºåºï¼šquestion,A,B,C,D,answerï¼‰
                csv_record = f'"{question_text}",{options[0]},{options[1]},{options[2]},{options[3]},{answer_letter}'

                record["response"] = csv_record  # âœ… æ·»åŠ  CSV æ ¼å¼å­—æ®µï¼ˆä¾¿äºåç»­ä¿å­˜ï¼‰

            elif q_type in ["short_answer", "open_discussion"]:
                # ç®€ç­”é¢˜å’Œè®¨è®ºé¢˜ç»Ÿä¸€ç»“æ„ï¼ˆå­—æ®µç›¸åŒï¼‰
                question_text = parsed.get("question", "").replace(",", "ï¼Œ")
                answer_text = parsed.get("answer", "").strip()

                record["response"] = {
                    "question": question_text,
                    "answer": answer_text
                }

            questions.append(record)

        return questions    


class ExpertAgent(BaseAgent):
    """ä¸“å®¶ Agentï¼Œç”¨äºè¯„ä¼°å’Œæ”¹è¿›è¯•é¢˜è´¨é‡"""

    def __init__(self, model="qwen"):
        super().__init__(name="ExpertAgent", model=model)
        from prompts.expert_prompts import EXPERT_PROMPTS_CN

        self.prompts = EXPERT_PROMPTS_CN

    def evaluate_and_refine_question(self, text, question_data, data_class):
        """
        è¯„ä¼°å¹¶æ”¹è¿›é—®é¢˜
        - question_data: åŒ…å«çŸ¥è¯†ç‚¹ã€é—®é¢˜ç±»å‹ã€åˆå§‹é—®é¢˜å’Œç­”æ¡ˆç­‰ä¿¡æ¯çš„å­—å…¸
        - data_class: æ•°æ®ç±»åˆ«ï¼Œç”¨äºå†³å®šæ‰©å±•çš„æ·±åº¦å’Œæ–¹å¼
        """
        knowledge_point = question_data["knowledge"]
        question_type = question_data["question_type"]

        # âœ… æ„é€ æ ‡å‡†è¾“å…¥æ–‡æœ¬ï¼šç”¨äºè¯„ä¼° or æ”¹å†™
        if question_type == "multiple_choice":
            eval_input = question_data.get("response", "")

        elif question_type in ["short_answer", "open_discussion"]:
            response = question_data.get("response", {})
            question_text = response.get("question", "").strip()
            answer_text = response.get("answer", "").strip()
            eval_input = f"é—®é¢˜ï¼š{question_text}\nå‚è€ƒç­”æ¡ˆï¼š{answer_text}"

        # âœ… Step 1: è¯•é¢˜è´¨é‡è¯„ä¼°
        expert_feedback = self.evaluate_quality(
            text, eval_input, knowledge_point, question_type, data_class
        )

        # âœ… Step 2: æ ¹æ®éœ€è¦è¿›è¡Œæ”¹å†™
        if expert_feedback.get("requires_refinement", False):
            expert_feedback["refined_response"] = self.refine_response(
                text, eval_input, knowledge_point, data_class, expert_feedback
            )
        else:
            expert_feedback["refined_response"] = ""

        return expert_feedback  # è¿”å›è¯„ä¼°æ•°æ®

    def evaluate_quality(self, text, response, 
                         knowledge_point, question_type, 
                         data_class="web"
                         ):
        """è¯„ä¼°è¯•é¢˜è´¨é‡å¹¶åˆ¤æ–­æ˜¯å¦éœ€è¦æ”¹è¿›"""
        prompt = self.prompts[f"evaluate_quality_{data_class}"].format(
            text=text,
            response=response,
            knowledge=knowledge_point,
            question_type=question_type,
        )

        evaluation_response = run_agent(prompt, model=self.model, num_gen=1, temperature=1)

        # æ–‡æœ¬æ ¼å¼è§£æ
        evaluation_response = re.sub(r"```(?:json)?|```", "", evaluation_response.strip())
        result = json.loads(evaluation_response)
        # å­—æ®µè½¬å°å†™ keyï¼ˆå…¼å®¹æ¨¡å‹å¤§å°å†™è¯¯å·®ï¼‰
        result = {k.lower(): v for k, v in result.items()}
        # 6. åˆ¤æ–­æ˜¯å¦å­—æ®µç¼ºå¤±æˆ–åˆ†æ•°å¤ªä½
        delete_data = any(
            result.get(k) is None or result.get(k) < 6
            for k in ["quality score", "relevance score", "consistency score"]
        )
        requires_refinement = result.get("quality score", 0) < 6

        # è¿”å›ç»“æ„
        return {
            "requires_refinement": requires_refinement,
            "delete_data": delete_data,
            "quality_score": result.get("quality score"),
            "relevance_score": result.get("relevance score"),
            "consistency_score": result.get("consistency score"),
            "improvement_suggestions": result.get("improvement suggestions", ""),
        }

    def refine_response(self, text, response, knowledge_point, data_class, expert_feedback):
        """
        æ ¹æ®è¯„ä¼°åé¦ˆæ”¹è¿›é—®é¢˜å’Œç­”æ¡ˆã€‚

        - text: åŸå§‹å†…å®¹
        - response: åˆå§‹ç”Ÿæˆçš„é—®é¢˜å’Œç­”æ¡ˆ
        - knowledge_point: çŸ¥è¯†ç‚¹
        - data_class: æ•°æ®ç±»åˆ«ï¼ˆå¦‚ books, articles, webï¼‰
        - expert_feedback: è¯„ä¼°åé¦ˆï¼ŒåŒ…å«æ”¹è¿›å»ºè®®
        """
        # è·å–ç”¨äºæ”¹è¿›çš„ prompt
        prompt_template = self.prompts[f"refine_response_{data_class}"]

        # å¡«å…… prompt æ¨¡æ¿
        prompt = prompt_template.format(
            text=text,
            response=response,
            knowledge=knowledge_point,
            feedback=expert_feedback.get("feedback", " "),
        )

        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ”¹è¿›åçš„å†…å®¹
        refined_response = run_agent(prompt, model=self.model, num_gen=1, temperature=1)
        refined_response = re.sub(r"```(?:json)?|```", "", refined_response.strip())
        parsed = json.loads(refined_response)
        return {
            "question": parsed.get("question", "").strip(),
            "answer": parsed.get("answer", "").strip()
        }


class VirtualTeacherAgent(BaseAgent):
    def __init__(self, name="VirtualTeacherAgent", model="qwen"):
        """åˆå§‹åŒ–è™šæ‹Ÿæ•™å¸ˆAgent"""
        super().__init__(name=name, model=model)
        from prompts.traininginstitute_prompts import CONVERSATION_PROMPTS_CN

        self.prompts = CONVERSATION_PROMPTS_CN

    def generate_thinking_chain(self, text, response, data_class):
        """ç”Ÿæˆæ€ç»´é“¾ï¼Œç”¨äºå¼•å¯¼å­¦ç”Ÿæ€è€ƒå’Œæ¨ç†ç­”æ¡ˆ"""
        if isinstance(response, list):
            response = response[0] + ", " + response[1]
        # è·å–æ€ç»´é“¾ç”Ÿæˆæ¨¡æ¿
        prompt_template = self.prompts.get(
            f"generate_chain_of_thought_{data_class}", {}
        )
        prompt = prompt_template.format(response=response)

        # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆæ€ç»´é“¾
        thinking_chain = run_agent(prompt, model=self.model, num_gen=1, temperature=0.8)
        thinking_chain = re.sub(r"```(?:json)?|```", "", thinking_chain.strip())
        parsed = json.loads(thinking_chain)
        # è·å–æ€ç»´é“¾
        formatted_thinking_chain = parsed.get("CoT", "").strip()
        # è¿”å›ç»“æœ
        return formatted_thinking_chain

    def convert_to_conversational_form(self, text, response, data_class):
        """å°†é€‰æ‹©é¢˜è½¬æ¢ä¸ºæ›´è‡ªç„¶çš„å£è¯­åŒ–å¯¹è¯å½¢å¼"""
        # è·å–å¯¹è¯è½¬æ¢æ¨¡æ¿
        prompt_template = self.prompts.get(f"convert_to_conversation_{data_class}", {})
        prompt = prompt_template.format(text=text, response=response)

        # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå¯¹è¯å½¢å¼
        conversational_response = run_agent(
            prompt, model=self.model, num_gen=1, temperature=0.7
        )
        conversational_response = re.sub(r"```(?:json)?|```", "", conversational_response.strip())
        # æ‹¼æ¥é—®é¢˜å’Œç­”æ¡ˆ
        try:
            parsed_response = json.loads(conversational_response)
            question = parsed_response.get("input", "").strip()
            answer = parsed_response.get("output", "").strip()
            
            # æ‹¼æ¥é—®é¢˜å’Œç­”æ¡ˆ
            conversational_form = f"é—®é¢˜: {question}\nå›ç­”: {answer}"

        except json.JSONDecodeError as e:
            # å¦‚æœè¿”å›çš„ç»“æœä¸èƒ½è¢«è§£æä¸º JSONï¼Œç›´æ¥è¿”å›åŸå§‹å†…å®¹
            conversational_form = conversational_response

        # è¿”å›æ‹¼æ¥åçš„å¯¹è¯å†…å®¹
        return conversational_form


    def cot_deepseek(self, response):
        """ç”Ÿæˆæ€ç»´é“¾ï¼Œç”¨äºå¼•å¯¼å­¦ç”Ÿæ€è€ƒå’Œæ¨ç†ç­”æ¡ˆ"""
        # è·å–æ€ç»´é“¾ç”Ÿæˆæ¨¡æ¿
        # prompt_template = self.prompts.get(
        #     f"generate_chain_of_thought_book", {}
        # )
        # prompt = prompt_template.format(response=response)

        prompt = response

        # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆæ€ç»´é“¾
        thinking_chain = run_agent(prompt, model=self.model, num_gen=1, temperature=1)

        # è¿”å›ç»“æœ
        return thinking_chain

